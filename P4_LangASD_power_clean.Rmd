---
title: "Assignment 1 - Language Development in ASD - part 4"
author: "JanCo. Unchained"
date: "October 10, 2018"
output: html_document
---

```{r setup}
knitr::opts_chunk$set(include = FALSE)

#load libraries
library(pacman)
p_load(lmerTest, tidyverse, simr, stats)

#load the test and train data
test <- read_csv("test_clean.csv")
train <- read_csv("language_dev_asd_clean_2.csv")
```


## Welcome to the fourth exciting part of the Language Development in ASD exercise

In this exercise we will assess how many participants we would need to adequately replicate our findings (ensuring our sample size is adequate, our alpha at 0.05 and our beta at 0.8).

### Exercise 1

How much power does your study have (if your model estimates are quite right)?
- [GitHub]Load your dataset, fit your favorite model, assess power for your main effects and interactions of interest.
- Report the power analysis and comment on what you can (or cannot) use its estimates for.

```{r}
#create model
HypesModel <- lmer(CHI_MLU ~ Diagnosis * VISIT + Diagnosis * I(VISIT^2) +
                    (1+VISIT +(VISIT^2)|SUBJ) , data = train, REML = FALSE)

#set seed as ensure replicability 
set.seed(911)

#calculate the power by running through 100 simulations
inter_diag_visit <- powerSim(HypesModel, simr::fixed("DiagnosisTD:VISIT", method = "t"), nsim = 100)

#display the parameters of the power analysis
inter_diag_visit #100% CI (96.38-100) - beta = 0.48
```

### Exercise 2

How would you perform a more conservative power analysis?
- Identify and justify a minimum effect size for each of your relevant effects
- [GitHub] take the model from exercise 1 and replace the effects with the minimum effect size that you'd accept.
- [GitHub] assess the power curve by Child.ID, identifying an ideal number of participants to estimate each effect
- [GitHub] if your power estimates do not reach an acceptable threshold simulate additional participants and repeat the previous analysis
- Report the power analysis and comment on what you can (or cannot) use its estimates for.
```{r}
#set a fixed estimate for the interaction effect
fixef(HypesModel)["DiagnosisTD:VISIT"] <- 0.25 #the smallest effect of interest

#set seed 
set.seed(911)

#do a power simulation
powerCurveV = powerCurve(HypesModel,
simr::fixed("DiagnosisTD:VISIT", method = "t"), along="SUBJ",nsim = 100)

#display the result of the power analysis
powerCurveV 

#plot the power curve
plot(powerCurveV)
```

 #### Simulate new data
```{r}
#set seed
set.seed(911)

#reload the model
HypesModel <- lmer(CHI_MLU ~ Diagnosis * VISIT + Diagnosis * I(VISIT^2) +
                    (1+VISIT +(VISIT^2)|SUBJ) , data = train, REML = FALSE)

#display the model
HypesModel

#replicate the training set and delete the values for the MLU of the children
train2 <- train
train2$CHI_MLU <- NA

#create new IDs for the children in the simulated set so there won't be an overlap between the training data and the simulated data
train2$SUBJ <- as.numeric(train2$SUBJ)
train2$SUBJ <- train2$SUBJ + 66
train2$SUBJ <- factor(train2$SUBJ)

#simulate new values of child MLU 
train2$CHI_MLU <- simulate(HypesModel, seed=1, newdata=train2, re.form=NA,
                        allow.new.levels=T)$sim_1

#conduct a t-test between the child MLU in the training set and the simulated set respectively
t.test(train$CHI_MLU, train2$CHI_MLU) #close enough? 

#get descriptive stats of child MLU in the two data sets
summary(train$CHI_MLU)
summary(train2$CHI_MLU)

#calculate standard deviation for child MLU in the two data sets
sd(train$CHI_MLU)
sd(train2$CHI_MLU)

#plot child MLU as a function of nr. visit for both data sets
ggplot(train2, aes(VISIT, CHI_MLU, color = Diagnosis))+
  geom_point()+
  geom_smooth()
ggplot(train, aes(VISIT, CHI_MLU, color = Diagnosis))+
  geom_point()+
  geom_smooth()

#combine the training set and the simulated set into one 
train3 <- rbind(train, train2)

#calculate the standard deviation for the combined set
sd(train3$CHI_MLU) #pretty close to original 

#recreate the model for the combined set
data_model <- lmer(CHI_MLU ~ Diagnosis * VISIT + Diagnosis * I(VISIT^2) +
                    (1+VISIT +(VISIT^2)|SUBJ), data = train3, REML = FALSE)

#set the same fixed estimate for the interaction effect as before
fixef(data_model)["DiagnosisTD:VISIT"] <- 0.25  

#do a power simulation
powerCurveNew = powerCurve(data_model,
simr::fixed("DiagnosisTD:VISIT", method = "t"), along="SUBJ", nsim = 100) 

#display the result of the power analysis
powerCurveNew #88 percent. 

#plot the power curve
plot(powerCurveNew) #somewhere between 109 - 122 participants we cross the 80% mark

#do a linear regression to find the number of approximate participants when the power is 80%
beta =  (122-109) / (88-77)
intercept = 122 - alpha * 88
intercept + beta * 80 
```

### Exercise 3

Assume you have only the resources to collect 30 kids (15 with ASD and 15 TDs). Identify the power for each relevant effect and discuss whether it's worth to run the study and why

```{r}
#set seed
set.seed(112)

#make a df consisting only of the ASD kids 
ASD_kid <- train %>%
  filter(Diagnosis == "ASD")

#create a df with 15 random ASD kids
fifteen_asd <- sample(unique(ASD_kid$SUBJ), 15)

#turn df into a vector
fifteen_asd <- as.vector(fifteen_asd)

#make a df consisting only of the TD kids 
TD_kid <- train %>%
  filter(Diagnosis == "TD")

#create a df with 15 random TD kids
fifteen_td <- sample(unique(TD_kid$SUBJ), 15)

#turn df into a vector
fifteen_td <- as.vector(fifteen_td)

#combine the vectors
fifteen_each <- c(fifteen_asd, fifteen_td)

#select the observations from the df
train_subset <- train %>%
  subset(SUBJ %in% fifteen_each)

#rerun the analysis
subset_model <- lmer(CHI_MLU ~ Diagnosis * VISIT + Diagnosis * I(VISIT^2) +
                    (1+VISIT +(VISIT^2)|SUBJ), data = train_subset, REML = FALSE)

#display the model
subset_model

#set seed
set.seed(911)

#run power analysis
subset_effect <- powerSim(subset_model, simr::fixed("DiagnosisTD:VISIT", method = "t"), nsim = 100)

#display the power analysis
subset_effect
```